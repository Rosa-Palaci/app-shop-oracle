{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbPXMsoNKkyr"
      },
      "source": [
        "# Fase 3.1: Construcción del Backend de IA (Python API)\n",
        "\n",
        "En esta subfase, desarrollamos el núcleo lógico que impulsará al Chatbot. Creamos una clase (`RetailIntelligenceBackend`) capaz de orquestar los servicios de OCI para responder a dos tipos de necesidades del usuario: recomendaciones pasivas (basadas en gustos) y búsquedas activas (basadas en intención)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbefUvDeOZUk"
      },
      "source": [
        "## Configuración del Entorno y Librerías\n",
        "Preparamos el entorno de ejecución instalando los SDKs de Oracle Cloud y las librerías de Machine Learning necesarias."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalamos las dependencias necesarias\n",
        "!pip install oci\n",
        "!pip install oracledb\n",
        "# !pip install scikit-surprise joblib\n",
        "# !pip install \"numpy<2\" --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyFq-17DP2PC",
        "outputId": "02332a4f-7149-44e0-c677-bf68d501aa2c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting oci\n",
            "  Downloading oci-2.164.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from oci) (2025.11.12)\n",
            "Requirement already satisfied: cryptography<46.0.0,>=3.2.1 in /usr/local/lib/python3.12/dist-packages (from oci) (43.0.3)\n",
            "Requirement already satisfied: pyOpenSSL<=25.1.0,>=17.5.0 in /usr/local/lib/python3.12/dist-packages (from oci) (24.2.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from oci) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2016.10 in /usr/local/lib/python3.12/dist-packages (from oci) (2025.2)\n",
            "Collecting circuitbreaker<3.0.0,>=1.3.1 (from oci)\n",
            "  Downloading circuitbreaker-2.1.3-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<46.0.0,>=3.2.1->oci) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.5.3->oci) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<46.0.0,>=3.2.1->oci) (2.23)\n",
            "Downloading oci-2.164.0-py3-none-any.whl (33.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.0/33.0 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading circuitbreaker-2.1.3-py3-none-any.whl (7.7 kB)\n",
            "Installing collected packages: circuitbreaker, oci\n",
            "Successfully installed circuitbreaker-2.1.3 oci-2.164.0\n",
            "Collecting oracledb\n",
            "  Downloading oracledb-3.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: cryptography>=3.2.1 in /usr/local/lib/python3.12/dist-packages (from oracledb) (43.0.3)\n",
            "Requirement already satisfied: typing_extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from oracledb) (4.15.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.2.1->oracledb) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.2.1->oracledb) (2.23)\n",
            "Downloading oracledb-3.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: oracledb\n",
            "Successfully installed oracledb-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eB8tE-9rC1A"
      },
      "outputs": [],
      "source": [
        "#Realizamos las importaciones correspondientes\n",
        "import oci\n",
        "import pandas as pd\n",
        "import oracledb\n",
        "# from surprise import SVD, Dataset, Reader, accuracy\n",
        "import os\n",
        "import joblib\n",
        "import array\n",
        "import json\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz3GjivwLKkk"
      },
      "source": [
        "### Inicialización de Clientes OCI\n",
        "\n",
        "\n",
        "Configuramos la autenticación con el archivo config y levantamos los clientes para Object Storage (almacenamiento de modelos) y OCI Generative AI (generación de embeddings). Es crucial usar el `GenerativeAiInferenceClient` para poder realizar inferencias en tiempo real."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHJW8HF8qtQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e31b3a-ed20-4bb5-dafe-3eefc6ce837c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clientes inicializados correctamente.\n"
          ]
        }
      ],
      "source": [
        "# Configuración de OCI\n",
        "NAMESPACE = 'ax5grcoay8ni'\n",
        "BUCKET_NAME = 'Team3'\n",
        "GENAI_ENDPOINT = 'https://inference.generativeai.us-chicago-1.oci.oraclecloud.com'\n",
        "GENAI_COMPARTMENT_ID = 'ocid1.compartment.oc1..aaaaaaaatjpti23mkvyvggtpv6kqujtabcigjaswynnfmhvjdjtkeaqfwakq' # Compartimento creado por el equipo\n",
        "\n",
        "# Cargamos la configuracion y los clientes (object storage y vision)\n",
        "try:\n",
        "    config = oci.config.from_file(\"config\", \"DEFAULT\")\n",
        "    # Cliente de Object Storage (para obtener el CSV)\n",
        "    object_storage_client = oci.object_storage.ObjectStorageClient(config)\n",
        "\n",
        "    # Cliente de inferencia OCI Gen AI\n",
        "    genai_inference_client = oci.generative_ai_inference.GenerativeAiInferenceClient(\n",
        "        config=config,\n",
        "        service_endpoint=GENAI_ENDPOINT\n",
        "    )\n",
        "    print(\"Clientes inicializados correctamente.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al inicializar clientes: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94jr_mfiOgXS"
      },
      "source": [
        "## Carga de Recursos (Modelos y Datos)\n",
        "El backend necesita tener acceso inmediato a los \"cerebros\" del sistema\n",
        "\n",
        "### Descarga del Modelo Basado en Embeddings\n",
        "\n",
        "El sistema emplea un modelo de recomendación embedding-based (`recommendation_model_v1.pkl`), el cual encapsula representaciones vectoriales para todo el catálogo de artículos.\n",
        "\n",
        "Dicho modelo se descarga desde OCI Object Storage al sistema de archivos local para ser cargado en la memoria RAM. Esto minimiza la latencia en cada predicción."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSM9HRYZp7yL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e670bd1-ecb0-43d1-e9b6-19cc9e093846",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo descargado exitosamente en: /content/recommendation_model_v1.pkl\n",
            "Tamaño: 413.08 MB\n"
          ]
        }
      ],
      "source": [
        "# Configuración del archivo\n",
        "MODEL_FILENAME = 'recommendation_model_v1.pkl'\n",
        "LOCAL_MODEL_PATH = f'/content/{MODEL_FILENAME}'\n",
        "OBJECT_NAME_IN_BUCKET = f\"models/{MODEL_FILENAME}\"\n",
        "\n",
        "try:\n",
        "    # Descargamos desde Object Storage\n",
        "    get_obj = object_storage_client.get_object(NAMESPACE, BUCKET_NAME, OBJECT_NAME_IN_BUCKET)\n",
        "\n",
        "    with open(LOCAL_MODEL_PATH, 'wb') as f:\n",
        "        for chunk in get_obj.data.raw.stream(1024 * 1024, decode_content=False):\n",
        "            f.write(chunk)\n",
        "\n",
        "    print(f\"Modelo descargado exitosamente en: {LOCAL_MODEL_PATH}\")\n",
        "    print(f\"Tamaño: {os.path.getsize(LOCAL_MODEL_PATH) / (1024*1024):.2f} MB\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error descargando modelo: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yt-breEqVmSr"
      },
      "outputs": [],
      "source": [
        "# --- CONFIGURACIÓN DE PARÁMETROS DB ---\n",
        "db_config = {\n",
        "    \"user\": \"ADMIN\",\n",
        "    \"password\": \"TecMonterreyTeam3\",\n",
        "    \"dsn\": \"team3vectordatabase_high\",\n",
        "    \"config_dir\": \"/content/wallet\",\n",
        "    \"wallet_location\": \"/content/wallet\",\n",
        "    \"wallet_password\": \"TecMonterreyTeam3\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S3WHXR7Mto7"
      },
      "source": [
        "### Conexión a Base de Datos Vectorial\n",
        "\n",
        "\n",
        "Definimos la función query y la configuración de conexión hacia nuestra Autonomous Database 26ai. Esta conexión es vital para acceder al catálogo de productos (ARTICLES_MODIFIED) y realizar búsquedas de similitud en la tabla vectorial (ARTICLE_EMBEDDINGS)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yh5JvGdlt4_n"
      },
      "outputs": [],
      "source": [
        "def query(sql, params=None):\n",
        "    connection = oracledb.connect(\n",
        "        user=\"ADMIN\",\n",
        "        password=\"TecMonterreyTeam3\",\n",
        "        dsn=\"team3vectordatabase_high\",\n",
        "        config_dir=\"/content/wallet\"\n",
        "    )\n",
        "\n",
        "    with connection.cursor() as cursor:\n",
        "        cursor.execute(sql, params or {})\n",
        "        result = cursor.fetchall()\n",
        "\n",
        "    connection.close()\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZPjHmHHOqqC"
      },
      "source": [
        "## El Cerebro Lógico: Clase RetailIntelligenceBackend\n",
        "Encapsulamos toda la lógica en una clase robusta diseñada para ser desplegada posteriormente como una API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E9hLWZ-PqQw"
      },
      "source": [
        "## Arquitectura del Backend\n",
        "\n",
        "\n",
        "La clase `RetailIntelligenceBackend` integra tres capacidades principales:\n",
        "\n",
        "\n",
        "1. **Recomendación Personalizada** (recommend_items_for_user): Utiliza el modelo basado en embeddings cargado en memoria para predecir el nivel de interés de un usuario por productos específicos.\n",
        "\n",
        "\n",
        "2. **Búsqueda Semántica** (search_by_text): Convierte la consulta del usuario en un vector usando OCI GenAI y realiza una búsqueda de distancia (**VECTOR_DISTANCE**) en la base de datos para encontrar productos conceptualmente similares.\n",
        "\n",
        "\n",
        "3. **Búsqueda Híbrida** (hybrid_search): Combina los resultados semánticos con las predicciones de gusto personal, aplicando una fórmula de ponderación dinámica para reordenar los resultados. Esto asegura que el usuario encuentre lo que busca, pero priorizando el estilo que le gusta."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RetailIntelligenceBackend:\n",
        "    def __init__(self, model_path, db_params, genai_client, compartment_id):\n",
        "\n",
        "        # Cargamos embeddings precomputados\n",
        "        try:\n",
        "            model_data = joblib.load(model_path)\n",
        "            self.article_ids = model_data[\"article_ids\"]\n",
        "            self.article_vectors = model_data[\"article_vectors\"]\n",
        "            # índice rápido article_id - posición\n",
        "            self.article_id_to_index = {\n",
        "                int(aid): idx for idx, aid in enumerate(self.article_ids)\n",
        "            }\n",
        "            print(f\"Modelo content-based cargado en memoria ({len(self.article_ids)} artículos).\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error cargando modelo content-based: {e}\")\n",
        "            self.article_ids = np.array([])\n",
        "            self.article_vectors = np.zeros((0, 0))\n",
        "            self.article_id_to_index = {}\n",
        "\n",
        "        self.db_params = db_params\n",
        "        self.genai_client = genai_client\n",
        "        self.compartment_id = compartment_id\n",
        "\n",
        "    def get_db_connection(self):\n",
        "        return oracledb.connect(**self.db_params)\n",
        "\n",
        "    def _extract_field_from_rag(self, rag_text, field_prefix):\n",
        "        if not rag_text:\n",
        "            return \"Desconocido\"\n",
        "        try:\n",
        "            parts = rag_text.split(';')\n",
        "            for part in parts:\n",
        "                if field_prefix in part:\n",
        "                    return part.replace(field_prefix, '').strip()\n",
        "            return \"General\"\n",
        "        except:\n",
        "            return \"General\"\n",
        "\n",
        "    # Funciones del modelo\n",
        "    def get_top_articles_for_user(self, customer_id, top_n=20):\n",
        "        sql = \"\"\"\n",
        "            SELECT \"article_id\", \"purchase_count\"\n",
        "            FROM INTERACTIONS_FOR_CF\n",
        "            WHERE \"customer_id\" = :user_id\n",
        "            ORDER BY \"purchase_count\" DESC, \"article_id\" ASC\n",
        "            FETCH FIRST :top_n ROWS ONLY\n",
        "        \"\"\"\n",
        "        conn = self.get_db_connection()\n",
        "        cursor = conn.cursor()\n",
        "        try:\n",
        "            cursor.execute(sql, user_id=customer_id, top_n=top_n)\n",
        "            rows = cursor.fetchall()\n",
        "            df = pd.DataFrame(rows, columns=[\"article_id\", \"purchase_count\"])\n",
        "            return df\n",
        "        finally:\n",
        "            cursor.close()\n",
        "            conn.close()\n",
        "\n",
        "    def build_user_profile_vector(self, top_df):\n",
        "\n",
        "        # top_df: DataFrame con columnas [\"article_id\", \"purchase_count\"]\n",
        "        # Usamos self.article_vectors (ya cargados del modelo) para construir el vector del usuario\n",
        "\n",
        "        vecs = []\n",
        "        weights = []\n",
        "        for _, row in top_df.iterrows():\n",
        "            aid = int(row[\"article_id\"])\n",
        "            idx = self.article_id_to_index.get(aid)\n",
        "            if idx is None:\n",
        "                continue\n",
        "            vecs.append(self.article_vectors[idx])\n",
        "            weights.append(row[\"purchase_count\"])\n",
        "\n",
        "        if not vecs:\n",
        "            return None\n",
        "\n",
        "        item_vecs = np.vstack(vecs)\n",
        "        weights = np.array(weights, dtype=np.float32)\n",
        "\n",
        "        user_vec = np.average(item_vecs, axis=0, weights=weights)\n",
        "\n",
        "        # normalizar\n",
        "        norm = np.linalg.norm(user_vec)\n",
        "        if norm > 0:\n",
        "            user_vec = user_vec / norm\n",
        "\n",
        "        return user_vec\n",
        "\n",
        "    def get_user_profile(self, customer_id, top_n=20):\n",
        "        top_df = self.get_top_articles_for_user(customer_id, top_n=top_n)\n",
        "        if top_df.empty:\n",
        "            return None\n",
        "        return self.build_user_profile_vector(top_df)\n",
        "\n",
        "\n",
        "    # FUNCIÓN RECOMENDACIÓN PERSONALIZADA\n",
        "    def recommend_items_for_user(self, customer_id, top_n=5):\n",
        "        print(f\"Generando recomendaciones para usuario: {customer_id[:10]}...\")\n",
        "\n",
        "        # Vector de gustos del usuario\n",
        "        user_vec = self.get_user_profile(customer_id, top_n=20)\n",
        "        if user_vec is None:\n",
        "            print(\"Usuario sin suficientes datos para construir perfil.\")\n",
        "            return []\n",
        "\n",
        "        if self.article_vectors.shape[0] == 0:\n",
        "            print(\"No hay embeddings cargados en el modelo.\")\n",
        "            return []\n",
        "\n",
        "        # Similitud coseno = producto punto\n",
        "        sims = self.article_vectors @ user_vec\n",
        "\n",
        "        # Top N artículos más similares\n",
        "        top_idx = np.argsort(-sims)[:top_n]\n",
        "        rec_ids = self.article_ids[top_idx]\n",
        "        rec_scores = sims[top_idx]\n",
        "\n",
        "        # Enriquecer con RAG y URL de imagen desde ARTICLES_MODIFIED\n",
        "        conn = self.get_db_connection()\n",
        "        cursor = conn.cursor()\n",
        "        try:\n",
        "            id_list = \",\".join(str(int(a)) for a in rec_ids)\n",
        "            sql_meta = f\"\"\"\n",
        "                SELECT \"article_id\", \"description_vector_rag\", \"img_url_team3\"\n",
        "                FROM ARTICLES_MODIFIED\n",
        "                WHERE \"article_id\" IN ({id_list})\n",
        "            \"\"\"\n",
        "            cursor.execute(sql_meta)\n",
        "            meta_rows = cursor.fetchall()\n",
        "\n",
        "            # indexamos score por id para fácil merge\n",
        "            score_by_id = {int(a): float(s) for a, s in zip(rec_ids, rec_scores)}\n",
        "\n",
        "            scored_items = []\n",
        "            for art_id, rag_text, img_url in meta_rows:\n",
        "                product_name = self._extract_field_from_rag(rag_text, \"NOMBRE: \")\n",
        "                product_group = self._extract_field_from_rag(rag_text, \"GRUPO: \")\n",
        "                product_color = self._extract_field_from_rag(rag_text, \"COLOR: \")\n",
        "\n",
        "                scored_items.append({\n",
        "                    \"article_id\": art_id,\n",
        "                    \"name\": product_name,\n",
        "                    \"group\": product_group,\n",
        "                    \"color\": product_color,\n",
        "                    \"image_url\": img_url,\n",
        "                    \"score\": round(score_by_id.get(int(art_id), 0.0), 4)\n",
        "                })\n",
        "\n",
        "            # Ordenamos por score\n",
        "            scored_items.sort(key=lambda x: x['score'], reverse=True)\n",
        "            return scored_items[:top_n]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error en recomendación content-based: {e}\")\n",
        "            return []\n",
        "        finally:\n",
        "            cursor.close()\n",
        "            conn.close()\n",
        "\n",
        "    # FUNCIÓN BÚSQUEDA SEMÁNTICA (EMBEDDINGS)\n",
        "    def search_by_text(self, query_text, top_n=5):\n",
        "        print(f\"Buscando semánticamente: '{query_text}'\")\n",
        "\n",
        "        try:\n",
        "            embed_details = oci.generative_ai_inference.models.EmbedTextDetails(\n",
        "                inputs=[query_text],\n",
        "                serving_mode=oci.generative_ai_inference.models.OnDemandServingMode(\n",
        "                    model_id=\"cohere.embed-english-v3.0\"\n",
        "                ),\n",
        "                truncate=\"END\",\n",
        "                compartment_id=self.compartment_id\n",
        "            )\n",
        "            response = self.genai_client.embed_text(embed_details)\n",
        "            query_vector = response.data.embeddings[0]\n",
        "        except Exception as e:\n",
        "            print(f\"Error GenAI: {e}\")\n",
        "            return []\n",
        "\n",
        "        conn = self.get_db_connection()\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        results = []\n",
        "        try:\n",
        "            sql_vector = \"\"\"\n",
        "                SELECT a.\"article_id\", a.\"description_vector_rag\", a.\"img_url_team3\",\n",
        "                       VECTOR_DISTANCE(e.\"vector\", :qv) as dist\n",
        "                FROM ARTICLE_EMBEDDINGS e\n",
        "                JOIN ARTICLES_MODIFIED a ON e.\"article_id\" = a.\"article_id\"\n",
        "                ORDER BY dist ASC\n",
        "                FETCH FIRST :top_n ROWS ONLY\n",
        "            \"\"\"\n",
        "\n",
        "            vector_array = array.array(\"f\", query_vector)\n",
        "            cursor.execute(sql_vector, qv=vector_array, top_n=top_n)\n",
        "\n",
        "            for row in cursor:\n",
        "                rag_text = row[1]\n",
        "\n",
        "                product_name = self._extract_field_from_rag(rag_text, \"NOMBRE: \")\n",
        "                product_group = self._extract_field_from_rag(rag_text, \"GRUPO: \")\n",
        "                product_color = self._extract_field_from_rag(rag_text, \"COLOR: \")\n",
        "\n",
        "                results.append({\n",
        "                    \"article_id\": row[0],\n",
        "                    \"name\": product_name,\n",
        "                    \"group\": product_group,\n",
        "                    \"color\": product_color,\n",
        "                    \"image_url\": row[2],\n",
        "                    \"similarity_score\": round(1 - row[3], 4)\n",
        "                })\n",
        "            return results\n",
        "        except Exception as e:\n",
        "            print(f\"Error en búsqueda vectorial: {e}\")\n",
        "            return []\n",
        "        finally:\n",
        "            cursor.close()\n",
        "            conn.close()\n",
        "\n",
        "    # FUNCIÓN BÚSQUEDA HÍBRIDA (texto + perfil de usuario con embeddings)\n",
        "    def hybrid_search(self, customer_id, query_text, top_n=5, weight_text=0.7, weight_user=0.3):\n",
        "        print(f\"Búsqueda Híbrida para {customer_id[:8]}...: '{query_text}'\")\n",
        "\n",
        "        # Candidatos por búsqueda semántica\n",
        "        semantic_results = self.search_by_text(query_text, top_n=50)\n",
        "        if not semantic_results:\n",
        "            return []\n",
        "\n",
        "        # Vector de usuario (perfil)\n",
        "        user_vec = self.get_user_profile(customer_id, top_n=20)\n",
        "        if user_vec is None:\n",
        "            # si no hay perfil, devolvemos solo semántico\n",
        "            return semantic_results[:top_n]\n",
        "\n",
        "        hybrid_results = []\n",
        "        max_personal = 0.0\n",
        "        temp_items = []\n",
        "\n",
        "        # Calculamos \"personal_score\" como similitud coseno entre user_vec y embedding del artículo\n",
        "        for item in semantic_results:\n",
        "            aid = int(item['article_id'])\n",
        "            idx = self.article_id_to_index.get(aid)\n",
        "            if idx is None:\n",
        "                personal_score = 0.0\n",
        "            else:\n",
        "                personal_score = float(self.article_vectors[idx] @ user_vec)\n",
        "\n",
        "            if personal_score > max_personal:\n",
        "                max_personal = personal_score\n",
        "\n",
        "            temp_items.append({**item, \"raw_personal\": personal_score})\n",
        "\n",
        "        if max_personal == 0:\n",
        "            max_personal = 1.0\n",
        "\n",
        "        # Combinamos semántico + perfil usuario\n",
        "        for item in temp_items:\n",
        "            normalized_personal = item['raw_personal'] / max_personal\n",
        "            semantic_score = item.get('similarity_score', 0.0)\n",
        "\n",
        "            final_score = (weight_text * semantic_score) + (weight_user * normalized_personal)\n",
        "\n",
        "            hybrid_results.append({\n",
        "                \"article_id\": item['article_id'],\n",
        "                \"name\": item['name'],\n",
        "                \"group\": item['group'],\n",
        "                \"color\": item['color'],\n",
        "                \"image_url\": item['image_url'],\n",
        "                \"semantic_score\": round(semantic_score, 4),\n",
        "                \"personal_score\": round(item['raw_personal'], 4),\n",
        "                \"final_score\": round(final_score, 4)\n",
        "            })\n",
        "\n",
        "        hybrid_results.sort(key=lambda x: x['final_score'], reverse=True)\n",
        "        return hybrid_results[:top_n]\n",
        "\n",
        "    # FUNCIÓN RECOMENDACIONES RELACIONADAS AL PRODUCTO (Item-to-Item + User)\n",
        "    # Para: \"Productos que te podrían interesar\" al dar click en un producto\n",
        "    def recommend_related_items(self, customer_id, anchor_article_id, top_n=5, weight_item=0.8, weight_user=0.2):\n",
        "        print(f\"Buscando similares a producto {anchor_article_id} para usuario {customer_id[:8]}...\")\n",
        "\n",
        "        # Obtenemos vector del producto ANCLA\n",
        "        anchor_idx = self.article_id_to_index.get(int(anchor_article_id))\n",
        "        if anchor_idx is None:\n",
        "            print(\"Producto ancla no encontrado en el modelo.\")\n",
        "            return []\n",
        "\n",
        "        anchor_vec = self.article_vectors[anchor_idx] # Vector del producto clickeado\n",
        "\n",
        "        # Obtenemos vector del USUARIO\n",
        "        user_vec = self.get_user_profile(customer_id) # Puede ser None\n",
        "\n",
        "        # Calculamos Similitud con el producto (Item-to-Item)\n",
        "        sims_item = self.article_vectors @ anchor_vec\n",
        "\n",
        "        # Similitud con el usuario (Personalización)\n",
        "        if user_vec is not None:\n",
        "            sims_user = self.article_vectors @ user_vec\n",
        "        else:\n",
        "            sims_user = np.zeros_like(sims_item) # Si no hay usuario, solo cuenta el item\n",
        "\n",
        "        # Combinamos Scores\n",
        "        # final = w1 * (Parecido al producto) + w2 * (Parecido a mis gustos)\n",
        "        final_scores = (weight_item * sims_item) + (weight_user * sims_user)\n",
        "\n",
        "        # Filtramos y ordenamos\n",
        "        # Queremos excluir el mismo producto que estamos viendo\n",
        "        final_scores[anchor_idx] = -1.0\n",
        "\n",
        "        top_idx = np.argsort(-final_scores)[:top_n]\n",
        "        rec_ids = self.article_ids[top_idx]\n",
        "        rec_scores = final_scores[top_idx]\n",
        "\n",
        "        return self._enrich_response(rec_ids, rec_scores)\n",
        "\n",
        "\n",
        "    # --- HELPERS ---\n",
        "    def _enrich_response(self, rec_ids, rec_scores):\n",
        "        \"\"\"Función auxiliar para ir a la BD por detalles dado una lista de IDs y Scores.\"\"\"\n",
        "        if len(rec_ids) == 0: return []\n",
        "\n",
        "        conn = self.get_db_connection()\n",
        "        cursor = conn.cursor()\n",
        "        try:\n",
        "            id_list = \",\".join(str(int(a)) for a in rec_ids)\n",
        "            sql_meta = f\"\"\"\n",
        "                SELECT \"article_id\", \"description_vector_rag\", \"img_url_team3\"\n",
        "                FROM ARTICLES_MODIFIED\n",
        "                WHERE \"article_id\" IN ({id_list})\n",
        "            \"\"\"\n",
        "            cursor.execute(sql_meta)\n",
        "            meta_rows = cursor.fetchall()\n",
        "\n",
        "            score_map = {int(a): float(s) for a, s in zip(rec_ids, rec_scores)}\n",
        "\n",
        "            results = []\n",
        "            for art_id, rag_text, img_url in meta_rows:\n",
        "                results.append({\n",
        "                    \"article_id\": art_id,\n",
        "                    \"name\": self._extract_field_from_rag(rag_text, \"NOMBRE: \"),\n",
        "                    \"group\": self._extract_field_from_rag(rag_text, \"GRUPO: \"),\n",
        "                    \"color\": self._extract_field_from_rag(rag_text, \"COLOR: \"),\n",
        "                    \"image_url\": img_url,\n",
        "                    \"score\": round(score_map.get(int(art_id), 0.0), 4)\n",
        "                })\n",
        "\n",
        "            # Reordenamos\n",
        "            results.sort(key=lambda x: x['score'], reverse=True)\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error enriqueciendo datos: {e}\")\n",
        "            return []\n",
        "        finally:\n",
        "            cursor.close()\n",
        "            conn.close()"
      ],
      "metadata": {
        "id": "PhVYsgWsLzOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk3Bz7JgWHue"
      },
      "source": [
        "## Instanciación y Pruebas Unitarias\n",
        "Validamos que el backend funcione correctamente antes de su despliegue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uLsy0IHWKGt"
      },
      "source": [
        "### Instanciación del Backend\n",
        "\n",
        "\n",
        "Creamos una instancia de la clase pasando las rutas de los modelos y las credenciales de base de datos. Confirmamos que el cliente de IA Generativa esté configurado correctamente para inferencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxfGFlIEWFgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6d6962a-58be-46fb-bcd9-96b1dac406d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo content-based cargado en memoria (105542 artículos).\n"
          ]
        }
      ],
      "source": [
        "# --- INSTANCIAMOS EL BACKEND ---\n",
        "backend = RetailIntelligenceBackend(\n",
        "    model_path=LOCAL_MODEL_PATH,\n",
        "    db_params=db_config,\n",
        "    genai_client=genai_inference_client,\n",
        "    compartment_id=GENAI_COMPARTMENT_ID\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAY5fox_WXU1"
      },
      "source": [
        "## Prueba de Capacidades\n",
        "\n",
        "\n",
        "Ejecutamos tres pruebas clave:\n",
        "\n",
        "\n",
        "1. **Recomendación Pura**: Verificamos que el sistema sugiera productos al usuario basándose solo en su historial (top 20 compras).\n",
        "\n",
        "\n",
        "2. **Búsqueda Semántica**: Probamos con una frase compleja (\"An elegant red dress for a party at night\") para validar que el motor entiende el contexto.\n",
        "\n",
        "\n",
        "3. **Búsqueda Híbrida**: Comprobamos que el sistema reordena los resultados semánticos basándose en el perfil del usuario (el puntaje \"Gusto\" altera el ranking final)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXjsGKaFtthY"
      },
      "source": [
        "**Prueba A**: Recomendación Personalizada (Embeddings).\n",
        "\n",
        "Vamos a pedirle recomendaciones para un usuario dentro de la base de datos."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tomamos un customer_id de prueba desde la BD\n",
        "test_user_id = query('SELECT \"customer_id\" FROM CUSTOMERS_MODIFIED FETCH FIRST 1 ROWS ONLY')[0][0]\n",
        "\n",
        "print(f\"Usuario de prueba: {test_user_id}\")\n",
        "\n",
        "# Llamada al backend\n",
        "recommendations = backend.recommend_items_for_user(test_user_id, top_n=5)\n",
        "\n",
        "print(\"\\n--- RECOMENDACIONES PERSONALIZADAS (HISTORIAL DEL USUARIO) ---\")\n",
        "for item in recommendations:\n",
        "    print(f\" Producto: {item['name']}\")\n",
        "    print(f\"   Categoría: {item['group']} |  Color: {item['color']}\")\n",
        "    print(f\"   Score similitud: {item['score']}\")\n",
        "    print(f\"   Img: {item['image_url']}\")\n",
        "    print(\"-\" * 30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKlKu2EHSqYj",
        "outputId": "0a809b5d-ef22-45a3-9499-cae7f57d61be",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usuario de prueba: 91dc9144398099a88f311f5f653d97ca199236d12be865d100c92d0da3c541f9\n",
            "Generando recomendaciones para usuario: 91dc914439...\n",
            "\n",
            "--- RECOMENDACIONES PERSONALIZADAS (HISTORIAL DEL USUARIO) ---\n",
            " Producto: Doutzen\n",
            "   Categoría: Garment Upper body |  Color: Dark Beige\n",
            "   Score similitud: 1.0\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axym8lqm5eyc/b/bucketia/o/images/066/0668537001.jpg\n",
            "------------------------------\n",
            " Producto: Doutzen\n",
            "   Categoría: Garment Upper body |  Color: Black\n",
            "   Score similitud: 0.9715\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axym8lqm5eyc/b/bucketia/o/images/066/0668537002.jpg\n",
            "------------------------------\n",
            " Producto: L Stitch Pile Coat\n",
            "   Categoría: Garment Upper body |  Color: Yellowish Brown\n",
            "   Score similitud: 0.8336\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axheitjen1w2/b/reto/o/images/077/0772829002.jpg\n",
            "------------------------------\n",
            " Producto: L Stitch Pile Coat\n",
            "   Categoría: Garment Upper body |  Color: Black\n",
            "   Score similitud: 0.8292\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axheitjen1w2/b/reto/o/images/077/0772829001.jpg\n",
            "------------------------------\n",
            " Producto: Premium Direction\n",
            "   Categoría: Garment Upper body |  Color: Light Pink\n",
            "   Score similitud: 0.826\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axym8lqm5eyc/b/bucketia/o/images/053/0534239001.jpg\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZoAsJAxtvpy"
      },
      "source": [
        "**Prueba B**: Búsqueda Semántica (Embeddings): Aquí buscaremos algo que no sea una palabra clave exacta, sino un concepto."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prueba de búsqueda natural\n",
        "search_query = \"An elegant red dress for a party at night\"\n",
        "\n",
        "# Llamada al backend usando embeddings\n",
        "results = backend.search_by_text(search_query, top_n=5)\n",
        "\n",
        "print(f\"\\n--- BÚSQUEDA SEMÁNTICA (EMBEDDINGS): '{search_query}' ---\")\n",
        "for item in results:\n",
        "    print(f\" Producto: {item['name']}\")\n",
        "    print(f\"   Categoría: {item['group']} |  Color: {item['color']}\")\n",
        "    print(f\"   Similitud: {item['similarity_score']}\")\n",
        "    print(f\"   Img: {item['image_url']}\")\n",
        "    print(\"-\" * 30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_76hnhEMUJRA",
        "outputId": "e7592dfe-9b9c-452d-b50a-ccade0f703b2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buscando semánticamente: 'An elegant red dress for a party at night'\n",
            "\n",
            "--- BÚSQUEDA SEMÁNTICA (EMBEDDINGS): 'An elegant red dress for a party at night' ---\n",
            " Producto: PARTY Harlow dress\n",
            "   Categoría: Garment Full body |  Color: Red\n",
            "   Similitud: 0.4976\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axheitjen1w2/b/reto/o/images/079/0796673002.jpg\n",
            "------------------------------\n",
            " Producto: EVE party dress SET\n",
            "   Categoría: Garment Full body |  Color: Dark Red\n",
            "   Similitud: 0.4933\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axym8lqm5eyc/b/bucketia/o/images/064/0648650001.jpg\n",
            "------------------------------\n",
            " Producto: Sam party dress\n",
            "   Categoría: Garment Full body |  Color: Red\n",
            "   Similitud: 0.4877\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axym8lqm5eyc/b/bucketia/o/images/067/0671302001.jpg\n",
            "------------------------------\n",
            " Producto: CNY partydress\n",
            "   Categoría: Garment Full body |  Color: Dark Red\n",
            "   Similitud: 0.4848\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axym8lqm5eyc/b/bucketia/o/images/070/0709865001.jpg\n",
            "------------------------------\n",
            " Producto: PARTY Eddie dress\n",
            "   Categoría: Garment Full body |  Color: Red\n",
            "   Similitud: 0.4783\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axheitjen1w2/b/reto/o/images/079/0796644002.jpg\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POhOGKuiFDwm"
      },
      "source": [
        "**Prueba C**: Ambos modelos unidos: Se utiliza la busqueda semantica para traer los productos mas similares semanticamente y utilizando Embeddings seleccionamos los productos que mas le podrian interesar al usuario con base en sus gustos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usuario y texto de prueba\n",
        "test_user_id = query('SELECT \"customer_id\" FROM CUSTOMERS_MODIFIED FETCH FIRST 1 ROWS ONLY')[0][0]\n",
        "search_query = \"An elegant red dress for a party at night\"\n",
        "\n",
        "print(f\"Usuario de prueba: {test_user_id}\")\n",
        "print(f\"Texto de búsqueda: '{search_query}'\")\n",
        "\n",
        "# Llamada al backend: híbrido (texto + historial)\n",
        "results = backend.hybrid_search(\n",
        "    customer_id=test_user_id,\n",
        "    query_text=search_query,\n",
        "    top_n=3,\n",
        "    weight_text=0.7,   # peso del significado del texto\n",
        "    weight_user=0.3    # peso del perfil del usuario\n",
        ")\n",
        "\n",
        "print(f\"\\n--- BÚSQUEDA HÍBRIDA (TEXTO + HISTORIAL) ---\")\n",
        "for item in results:\n",
        "    print(f\" Producto: {item['name']}\")\n",
        "    print(f\"   Categoría: {item['group']} |  Color: {item['color']}\")\n",
        "    print(f\"   Score semántico (texto): {item['semantic_score']}\")\n",
        "    print(f\"   Score personal (usuario): {item['personal_score']}\")\n",
        "    print(f\"   Score final combinado:    {item['final_score']}\")\n",
        "    print(f\"   Img: {item['image_url']}\")\n",
        "    print(\"-\" * 40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDD-6l5GVFd0",
        "outputId": "ed79ac0e-fd83-4223-a892-4e3a84c5a2e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usuario de prueba: 0e5c9909c03c8a37991870114712c46b3ae0e7902220d8c4bb2a5390f35fed43\n",
            "Texto de búsqueda: 'An elegant red dress for a party at night'\n",
            "Búsqueda Híbrida para 0e5c9909...: 'An elegant red dress for a party at night'\n",
            "Buscando semánticamente: 'An elegant red dress for a party at night'\n",
            "\n",
            "--- BÚSQUEDA HÍBRIDA (TEXTO + HISTORIAL) ---\n",
            " Producto: Moonlight dress\n",
            "   Categoría: Garment Full body |  Color: Dark Red\n",
            "   Score semántico (texto): 0.4766\n",
            "   Score personal (usuario): 0.7583\n",
            "   Score final combinado:    0.6336\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axym8lqm5eyc/b/bucketia/o/images/054/0542443004.jpg\n",
            "----------------------------------------\n",
            " Producto: CHRISTMAS nightgown\n",
            "   Categoría: Nightwear |  Color: Dark Red\n",
            "   Score semántico (texto): 0.4765\n",
            "   Score personal (usuario): 0.7216\n",
            "   Score final combinado:    0.619\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axym8lqm5eyc/b/bucketia/o/images/059/0595569001.jpg\n",
            "----------------------------------------\n",
            " Producto: EVE party dress SET\n",
            "   Categoría: Garment Full body |  Color: Dark Red\n",
            "   Score semántico (texto): 0.4933\n",
            "   Score personal (usuario): 0.6872\n",
            "   Score final combinado:    0.6172\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axym8lqm5eyc/b/bucketia/o/images/064/0648650001.jpg\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prueba D**: Se utiliza la similitud entre productos para traer los productos más similares utilizando Embeddings y con el gusto personal seleccionamos los productos que más le podrían interesar al usuario para re-ordenar estos productos."
      ],
      "metadata": {
        "id": "qEHBfaRD29GO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prueba de la funcionalidad Item-to-Item\n",
        "# Usamos el usuario de prueba\n",
        "test_user_id = \"0e5c9909c03c8a37991870114712c46b3ae0e7902220d8c4bb2a5390f35fed43\"\n",
        "\n",
        "# Simulamos que el usuario dio click en el \"PARTY Harlow dress\"\n",
        "clicked_product_id = 796673002\n",
        "\n",
        "# Llamada a la nueva función\n",
        "related_items = backend.recommend_related_items(\n",
        "    customer_id=test_user_id,\n",
        "    anchor_article_id=clicked_product_id,\n",
        "    top_n=5,\n",
        "    weight_item=0.8, # Priorizamos que se parezca al producto\n",
        "    weight_user=0.2  # Pero con un toque del gusto del usuario\n",
        ")\n",
        "\n",
        "print(f\"\\n--- PRODUCTOS RELACIONADOS (Porque viste el {clicked_product_id}) ---\")\n",
        "for item in related_items:\n",
        "    print(f\" Producto: {item['name']}\")\n",
        "    print(f\"   Categoría: {item['group']} | Color: {item['color']}\")\n",
        "    print(f\"   Score Híbrido: {item['score']}\")\n",
        "    print(f\"   Img: {item['image_url']}\")\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh-L_o0i1OQs",
        "outputId": "00f41441-e040-4bda-8c50-61e6db3fe3ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buscando similares a producto 796673002 para usuario 0e5c9909...\n",
            "\n",
            "--- PRODUCTOS RELACIONADOS (Porque viste el 796673002) ---\n",
            " Producto: PARTY Harlow dress\n",
            "   Categoría: Garment Full body | Color: Black\n",
            "   Score Híbrido: 0.9193\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axheitjen1w2/b/reto/o/images/079/0796673001.jpg\n",
            "------------------------------\n",
            " Producto: Harlow dress\n",
            "   Categoría: Garment Full body | Color: White\n",
            "   Score Híbrido: 0.7785\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axym8lqm5eyc/b/bucketia/o/images/054/0549527001.jpg\n",
            "------------------------------\n",
            " Producto: PARTY Love dress\n",
            "   Categoría: Garment Full body | Color: Dark Pink\n",
            "   Score Híbrido: 0.772\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axheitjen1w2/b/reto/o/images/079/0796646001.jpg\n",
            "------------------------------\n",
            " Producto: Make a scene dress\n",
            "   Categoría: Garment Full body | Color: Dark Red\n",
            "   Score Híbrido: 0.7639\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axym8lqm5eyc/b/bucketia/o/images/057/0573059003.jpg\n",
            "------------------------------\n",
            " Producto: PARTY Liz dress\n",
            "   Categoría: Garment Full body | Color: Off White\n",
            "   Score Híbrido: 0.7578\n",
            "   Img: https://objectstorage.us-chicago-1.oraclecloud.com/n/axheitjen1w2/b/reto/o/images/079/0796652001.jpg\n",
            "------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}